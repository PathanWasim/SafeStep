# ğŸ§­ SafeStep - Advanced Indoor Navigation System

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.8+-green.svg)](https://opencv.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **AI-Powered Indoor Navigation System for Visually Impaired and Accessibility**
>
> SafeStep is a comprehensive indoor navigation system that combines advanced computer vision, artificial intelligence, and multi-modal accessibility features to provide real-time navigation assistance in indoor environments.

## ğŸŒŸ Key Features

### ğŸ¤– AI-Powered Detection

* **Real-time Object Detection**: YOLO-based detection of people, obstacles, doors, stairs, furniture
* **Depth Estimation**: MiDaS model for 3D depth mapping and distance calculation
* **Risk Assessment**: Intelligent risk level classification (high/medium/low/minimal)
* **Distance Estimation**: Accurate distance calculation to detected objects

### ğŸ¤ Multi-Modal Accessibility

* **Voice Assistant**: Natural language processing for voice commands and feedback
* **Gesture Recognition**: Hand gesture control using MediaPipe
* **Text-to-Speech**: Real-time audio feedback for navigation instructions
* **Emergency Mode**: Quick activation for urgent situations

### ğŸ§­ Advanced Navigation

* **Path Planning**: A\* algorithm with obstacle avoidance
* **Real-time Analytics**: Comprehensive detection logging and analytics
* **Safety Monitoring**: Continuous safety assessment and warnings
* **Multiple Modes**: Autonomous, Guided, Exploration, and Emergency modes

### ğŸ–¥ï¸ Modern User Interface

* **Dark Theme**: Modern CustomTkinter interface
* **Real-time Visualization**: Live video feed with detection overlays
* **Analytics Dashboard**: Comprehensive statistics and data export
* **Responsive Design**: Adaptive layout for different screen sizes

## ğŸ“‹ System Requirements

### Minimum Requirements

* **Python 3.8+** (3.9+ recommended)
* **4GB RAM** (8GB+ recommended)
* **Webcam** or USB camera
* **Microphone** (for voice commands)
* **Speakers/Headphones** (for voice feedback)

### Recommended

* **GPU with CUDA** (for faster AI processing)
* **8GB+ RAM** (for optimal performance)
* **High-resolution camera** (720p or higher)
* **Windows/Linux/macOS** (all supported)

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/PathanWasim/SafeStep.git
cd SafeStep
```

### 2. Run Installation Script

```bash
python install.py
```

This automated script will:

* âœ… Check Python version compatibility
* âœ… Install PyTorch with appropriate CUDA support
* âœ… Install all required dependencies
* âœ… Set up system-specific dependencies
* âœ… Create configuration file
* âœ… Test all imports

### 3. Start the Application

```bash
# Run the modular version (recommended)
python main_new.py
# Or run the original version
python main.py
```

## ğŸ“ Project Structure

```
SafeStep/
â”œâ”€â”€ main_new.py              # ğŸš€ Main application (modular version)
â”œâ”€â”€ main.py                  # Original monolithic version
â”œâ”€â”€ install.py               # ğŸ”§ Automated installation script
â”œâ”€â”€ requirements.txt         # ğŸ“¦ Python dependencies
â”œâ”€â”€ config.json              # âš™ï¸ Configuration settings
â”œâ”€â”€ README.md                # ğŸ“– This documentation
â”œâ”€â”€ README_MODULAR.md        # ğŸ“š Detailed modular architecture
â”œâ”€â”€ .gitignore               # ğŸš« Git ignore rules
â”‚
â”œâ”€â”€ ai_models/               # ğŸ¤– AI and ML components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ depth_estimator.py   # MiDaS depth estimation
â”‚   â””â”€â”€ object_detector.py   # YOLO object detection
â”‚
â”œâ”€â”€ sensors/                 # ğŸ“¡ Hardware interfaces
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ camera_manager.py    # Camera management
â”‚   â”œâ”€â”€ gesture_controller.py# MediaPipe gestures
â”‚   â””â”€â”€ voice_assistant.py   # Speech recognition & TTS
â”‚
â”œâ”€â”€ navigation/              # ğŸ§­ Navigation logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ path_planner.py      # Path planning & obstacle avoidance
â”‚
â”œâ”€â”€ database/                # ğŸ’¾ Data persistence
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ database_manager.py  # SQLite database operations
â”‚
â”œâ”€â”€ models/                  # ğŸ“Š Data structures
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ data_models.py       # Core data classes & enums
â”‚
â”œâ”€â”€ ui/                      # ğŸ–¥ï¸ User interface
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main_window.py       # CustomTkinter UI components
â”‚
â””â”€â”€ Reports/                 # ğŸ“Š Research and documentation
    â”œâ”€â”€ Object Detection final.pptx
    â””â”€â”€ Research Paper .pdf
```

## âš™ï¸ Configuration

The system uses `config.json` for configuration:

```json
{
  "camera": {
    "device_id": 0,
    "resolution": [1280, 720],
    "fps": 60
  },
  "detection": {
    "confidence_threshold": 0.5,
    "nms_threshold": 0.4,
    "model_path": "yolo11n.pt"
  },
  "navigation": {
    "safe_distance": 2.0,
    "warning_distance": 1.0,
    "emergency_distance": 0.5
  },
  "voice": {
    "enabled": true,
    "language": "en-US",
    "rate": 150,
    "volume": 0.9
  },
  "ui": {
    "theme": "dark",
    "window_size": [1600, 1000],
    "fullscreen": false
  }
}
```

## ğŸ® Usage Guide

### Voice Commands

* **"Navigate to bathroom"** - Find nearest restroom
* **"Find exit"** - Locate nearest exit
* **"Where am I?"** - Get current location
* **"What do you see?"** - Describe surroundings
* **"Emergency"** - Activate emergency mode

### Gesture Controls

* **ğŸ–ï¸ Open Palm** - Stop navigation
* **ğŸ‘† Pointing** - Forward direction
* **ğŸ‘ˆ Left Hand** - Turn left
* **ğŸ‘‰ Right Hand** - Turn right
* **âœ‹ Raised Hand** - Help request

### UI Controls

* **Mode Selector** - Switch between navigation modes
* **Confidence Slider** - Adjust detection sensitivity
* **Voice Toggle** - Enable/disable voice assistant
* **Emergency Button** - Quick emergency activation
* **Export Data** - Export analytics and logs
  \`\`
